{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End Multiclass Image Classification Example in C#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Introduction](#Introduction)\n",
    "2. [Prerequisites](#Prerequisites)\n",
    "  1. [Lifecycle Configuration](#Lifecycle-Configuration)\n",
    "  2. [Required Packages](#Required-Packages)\n",
    "  3. [Data Preparation](#Data-Preparation)\n",
    "3. [Train the ResNet Model](#Train-the-ResNet-Model)\n",
    "4. [Deploy the Model](#Deploy-the-Model)\n",
    "5. [Use the Model to perform Inferences](#Use-the-Model-to-perform-Inferences)\n",
    "  1. [Create endpoint configuration](#Create-endpoint-configuration) \n",
    "  2. [Create endpoint](#Create-endpoint) \n",
    "  3. [Perform Inferences](#Perform-Inferences)\n",
    "  4. [Clean up](#Clean-up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Welcome to our end-to-end example of distributed image classification algorithm. In this demo, we will use the Amazon sagemaker image classification algorithm to train on the [caltech-256 dataset](http://www.vision.caltech.edu/Image_Datasets/Caltech256/). \n",
    "\n",
    "This example builds upon the Python based example found in the [AWS Samples GitHub Repo](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/imageclassification_caltech/Image-classification-fulltraining.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lifecycle Configuration\n",
    "\n",
    "In order to enable your SageMaker Notebook environments to run this Notebook with the C# Kernel, you need to have already created and associated a customized [Lifecycle Configuration](https://docs.aws.amazon.com/sagemaker/latest/dg/notebook-lifecycle-config.html) with this Notebook Instance using the Configuration Script provided in this repo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by including all of the required NuGet Packages for the Notebook\n",
    "- SageMaker SDK\n",
    "- AWS S3 SDK\n",
    "- NewtonSoft Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r \"nuget:AWSSDK.SageMaker, 3.3.112.3\"\n",
    "#r \"nuget:AWSSDK.SageMakerRuntime, 3.3.101.49\"\n",
    "#r \"nuget:AWSSDK.S3, 3.3.110.45\"\n",
    "#r \"nuget:Newtonsoft.Json, 12.0.3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the above packages have been installed, include the relevant Namespaces into the application scope "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Amazon.SageMaker;\n",
    "using Amazon.SageMaker.Model;\n",
    "\n",
    "using Amazon.SageMakerRuntime;\n",
    "using Amazon.SageMakerRuntime.Model;\n",
    "\n",
    "using Amazon.S3;\n",
    "using Amazon.S3.Model;\n",
    "\n",
    "using Newtonsoft.Json;\n",
    "\n",
    "using System.IO;\n",
    "using System.Net;\n",
    "using System.Net.Http;\n",
    "using System.Net.Http.Headers;\n",
    "using System.Threading.Tasks;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the various AWS SDK Client Objects that will be used to make API calls to the AWS Services, and the WebClient that will be used to download files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static AmazonS3Client s3Client = new AmazonS3Client();\n",
    "AmazonSageMakerClient smClient = new AmazonSageMakerClient();\n",
    "AmazonSageMakerRuntimeClient smrClient = new AmazonSageMakerRuntimeClient();\n",
    "WebClient webClient = new WebClient();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the required Training Data and Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webClient.DownloadFile(\"http://data.mxnet.io/data/caltech-256/caltech-256-60-train.rec\", \"caltech-256-60-train.rec\");\n",
    "webClient.DownloadFile(\"http://data.mxnet.io/data/caltech-256/caltech-256-60-val.rec\", \"caltech-256-60-val.rec\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the proper S3 paths/locations where the training/validation data will be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "String bucketName = \"dotnet-sagemaker-bucket\";\n",
    "String trainKey = \"image-classification-full-training/train\";\n",
    "String validationKey = \"image-classification-full-training/validation\";\n",
    "String s3Train = String.Format(\"s3://{0}/{1}/\",bucketName,trainKey);\n",
    "String s3Validation = String.Format(\"s3://{0}/{1}/\",bucketName,validationKey);\n",
    "String trainFile = String.Format(\"{0}/caltech-256-60-train.rec\",trainKey);\n",
    "String validationFile = String.Format(\"{0}/caltech-256-60-val.rec\",validationKey);\n",
    "Console.WriteLine(s3Train);\n",
    "Console.WriteLine(s3Validation);\n",
    "Console.WriteLine(trainFile);\n",
    "Console.WriteLine(validationFile);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the function that will be used to upload files into the S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static async Task UploadToS3(string s3Bucket, string s3Key, string filePath)\n",
    "        {\n",
    "            try\n",
    "            {\n",
    "                var putRequest = new PutObjectRequest\n",
    "                {\n",
    "                    BucketName = s3Bucket,\n",
    "                    Key = s3Key,\n",
    "                    FilePath = filePath,\n",
    "                    ContentType = \"text/plain\"\n",
    "                };\n",
    "                PutObjectResponse response1 = await s3Client.PutObjectAsync(putRequest);\n",
    "            }\n",
    "            catch (AmazonS3Exception e)\n",
    "            {\n",
    "                Console.WriteLine(\n",
    "                        \"Error encountered ***. Message:'{0}' when writing an object\"\n",
    "                        , e.Message);\n",
    "            }\n",
    "            catch (Exception e)\n",
    "            {\n",
    "                Console.WriteLine(\n",
    "                    \"Unknown encountered on server. Message:'{0}' when writing an object\"\n",
    "                    , e.Message);\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy all of the downloaded Training and Validation data into the S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UploadToS3(bucketName,trainFile,@\"./caltech-256-60-train.rec\").Wait();\n",
    "UploadToS3(bucketName,validationFile,@\"./caltech-256-60-val.rec\").Wait();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the ResNet Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo, we are using [Caltech-256](http://www.vision.caltech.edu/Image_Datasets/Caltech256/) dataset, which contains 30608 images of 256 objects. For the training and validation data, we follow the splitting scheme in this MXNet [example](https://github.com/apache/incubator-mxnet/blob/master/example/image-classification/data/caltech256.sh). In particular, it randomly selects 60 images per class for training, and uses the remaining data for validation. The algorithm takes `RecordIO` file as input. The user can also provide the image files as input, which will be converted into `RecordIO` format using MXNet's [im2rec](https://mxnet.incubator.apache.org/how_to/recordio.html?highlight=im2rec) tool. It takes around 50 seconds to converted the entire Caltech-256 dataset (~1.2GB) on a p2.xlarge instance. However, for this demo, we will use record io format.\n",
    "\n",
    "Once we have the data available in the correct format for training, the next step is to actually train the model using the data. After setting training parameters, we kick off training, and poll for status until training is completed.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An IAM role is required for the SageMaker service to use when it is running the training job and creating the Model. Extract this role from the current running Notebook instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DescribeNotebookInstanceRequest dniReq = new DescribeNotebookInstanceRequest() {\n",
    "    NotebookInstanceName = \"dotNetV3-1\"\n",
    "};\n",
    "DescribeNotebookInstanceResponse dniResp = await smClient.DescribeNotebookInstanceAsync(dniReq);\n",
    "Console.WriteLine(dniResp.RoleArn);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new Training Job Request object with all required parameters. To see a detailed description of what the parameters mean, refer to the [Python Sample](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/imageclassification_caltech/Image-classification-fulltraining.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string jobName = String.Format(\"DEMO-imageclassification-{0}\",DateTime.Now.ToString(\"yyyy-MM-dd-hh-mmss\"));\n",
    "\n",
    "CreateTrainingJobRequest ctrRequest = new CreateTrainingJobRequest(){\n",
    "    AlgorithmSpecification = new AlgorithmSpecification(){\n",
    "        TrainingImage = \"433757028032.dkr.ecr.us-west-2.amazonaws.com/image-classification:1\",\n",
    "        TrainingInputMode = \"File\"  \n",
    "    },\n",
    "    RoleArn = dniResp.RoleArn,\n",
    "    OutputDataConfig = new OutputDataConfig(){\n",
    "        S3OutputPath = String.Format(@\"s3://{0}/{1}/output\",bucketName,jobName)\n",
    "    },\n",
    "    ResourceConfig = new ResourceConfig(){\n",
    "        InstanceCount = 1,\n",
    "        InstanceType = Amazon.SageMaker.TrainingInstanceType.MlP2Xlarge,\n",
    "        VolumeSizeInGB = 50\n",
    "    },\n",
    "    TrainingJobName = jobName,\n",
    "    HyperParameters = new Dictionary<string,string>() {\n",
    "        {\"image_shape\",\"3,224,224\"},\n",
    "        {\"num_layers\",\"18\"},\n",
    "        {\"num_training_samples\",\"15420\"},\n",
    "        {\"num_classes\",\"257\"},\n",
    "        {\"mini_batch_size\",\"64\"},\n",
    "        {\"epochs\",\"10\"},\n",
    "        {\"learning_rate\",\"0.01\"}\n",
    "    },\n",
    "    StoppingCondition = new StoppingCondition(){\n",
    "        MaxRuntimeInSeconds = 360000\n",
    "    },\n",
    "    InputDataConfig = new List<Amazon.SageMaker.Model.Channel>(){\n",
    "        new Amazon.SageMaker.Model.Channel() {\n",
    "            ChannelName = \"train\",\n",
    "            ContentType = \"application/x-recordio\",\n",
    "            CompressionType = Amazon.SageMaker.CompressionType.None,\n",
    "            DataSource = new Amazon.SageMaker.Model.DataSource(){\n",
    "                S3DataSource = new Amazon.SageMaker.Model.S3DataSource(){\n",
    "                    S3DataType = Amazon.SageMaker.S3DataType.S3Prefix,\n",
    "                    S3Uri = s3Train,\n",
    "                    S3DataDistributionType = Amazon.SageMaker.S3DataDistribution.FullyReplicated\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        new Amazon.SageMaker.Model.Channel(){\n",
    "            ChannelName = \"validation\",\n",
    "            ContentType = \"application/x-recordio\",\n",
    "            CompressionType = Amazon.SageMaker.CompressionType.None,\n",
    "            DataSource = new Amazon.SageMaker.Model.DataSource(){\n",
    "                S3DataSource = new Amazon.SageMaker.Model.S3DataSource(){\n",
    "                    S3DataType = Amazon.SageMaker.S3DataType.S3Prefix,\n",
    "                    S3Uri = s3Validation,\n",
    "                    S3DataDistributionType = Amazon.SageMaker.S3DataDistribution.FullyReplicated\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "};"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit the request for the Training job to be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CreateTrainingJobResponse ctrResponse = await smClient.CreateTrainingJobAsync(ctrRequest);\n",
    "Console.WriteLine(ctrResponse.TrainingJobArn);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poll the status of the submitted Training job - Run the next block a few times until the job has been completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DescribeTrainingJobRequest tjReq = new DescribeTrainingJobRequest(){\n",
    "    TrainingJobName = jobName\n",
    "};\n",
    "DescribeTrainingJobResponse tjResp = await smClient.DescribeTrainingJobAsync(tjReq);\n",
    "Console.WriteLine(tjResp.TrainingJobStatus);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the Training job above has been completed, it is time to make use of the trained model - first we have to deploy the Model. Create the request object with all required parameters and make API call to generate the Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string modelName = String.Format(\"DEMO-full-image-classification-model-{0}\",DateTime.Now.ToString(\"yyyy-MM-dd-hh-mmss\"));\n",
    "Console.WriteLine(modelName);\n",
    "\n",
    "CreateModelRequest modelRequest = new CreateModelRequest(){\n",
    "    ModelName = modelName,\n",
    "    ExecutionRoleArn = dniResp.RoleArn,\n",
    "    PrimaryContainer = new ContainerDefinition(){\n",
    "        Image = \"433757028032.dkr.ecr.us-west-2.amazonaws.com/image-classification:latest\",\n",
    "        ModelDataUrl = tjResp.ModelArtifacts.S3ModelArtifacts\n",
    "    }\n",
    "};\n",
    "\n",
    "CreateModelResponse modelResponse = await smClient.CreateModelAsync(modelRequest);\n",
    "Console.WriteLine(modelResponse.ModelArn);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Model to perform Inferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now host the model with an endpoint and perform realtime inference.\n",
    "\n",
    "This section involves several steps,\n",
    "\n",
    "1. [Create endpoint configuration](#Create-endpoint-configuration) - Create a configuration defining an endpoint.\n",
    "2. [Create endpoint](#Create-endpoint) - Use the configuration to create an inference endpoint.\n",
    "3. [Perform Inferences](#Perform-Inferences) - Perform inference on some input data using the endpoint.\n",
    "4. [Clean up](#Clean-up) - Delete the endpoint and model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create endpoint configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string epConfName = String.Format(\"{0}-EndPointConfig\",jobName);\n",
    "Console.WriteLine(epConfName);\n",
    "\n",
    "CreateEndpointConfigRequest epConfReq = new CreateEndpointConfigRequest(){\n",
    "    EndpointConfigName = epConfName,\n",
    "    ProductionVariants = new List<ProductionVariant>(){\n",
    "        new ProductionVariant() {\n",
    "            InstanceType = Amazon.SageMaker.ProductionVariantInstanceType.MlP28xlarge,\n",
    "            InitialInstanceCount = 1,\n",
    "            ModelName = modelName,\n",
    "            VariantName = \"AllTraffic\"\n",
    "        }\n",
    "    }\n",
    "};\n",
    "\n",
    "CreateEndpointConfigResponse epConfResp = await smClient.CreateEndpointConfigAsync(epConfReq);\n",
    "Console.WriteLine(epConfResp.EndpointConfigArn);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create endpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string epName = String.Format(\"{0}-EndPoint\",jobName);\n",
    "Console.WriteLine(epName);\n",
    "\n",
    "CreateEndpointRequest epReq = new CreateEndpointRequest(){\n",
    "    EndpointName = epName,\n",
    "    EndpointConfigName = epConfName\n",
    "};\n",
    "\n",
    "CreateEndpointResponse epResp = await smClient.CreateEndpointAsync(epReq);\n",
    "Console.WriteLine(epResp.EndpointArn);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poll the status Endpoint creation - Run the next block a few times until Endpoint status shows 'InService'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DescribeEndpointRequest deReq = new DescribeEndpointRequest(){\n",
    "    EndpointName = epName\n",
    "};\n",
    "DescribeEndpointResponse deResp = await smClient.DescribeEndpointAsync(deReq);\n",
    "Console.WriteLine(deResp.EndpointStatus);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Inferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the Endpoint is InService, it is ready to be invoked to retrieve Inferences/Predictions. Download 2 sample images that will be used for this purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webClient.DownloadFile(\"http://www.vision.caltech.edu/Image_Datasets/Caltech256/images/008.bathtub/008_0007.jpg\", \"008_0007.jpg\");\n",
    "webClient.DownloadFile(\"http://www.vision.caltech.edu/Image_Datasets/Caltech256/images/008.bathtub/008_0009.jpg\", \"008_0009.jpg\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the above 2 downloaded files, the next step is to load the file into memory and Invoke the endpoint with the file as payload to retrieve a Prediction about the image. The response will include an array of 'Probability' percentages for each of the known categories for the Training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//Load the known categories into memory\n",
    "String[] categoriesArray = new String[]{\"ak47\", \"american-flag\", \"backpack\", \"baseball-bat\", \"baseball-glove\", \"basketball-hoop\", \"bat\", \"bathtub\", \"bear\", \"beer-mug\", \"billiards\", \"binoculars\", \"birdbath\", \"blimp\", \"bonsai-101\", \"boom-box\", \"bowling-ball\", \"bowling-pin\", \"boxing-glove\", \"brain-101\", \"breadmaker\", \"buddha-101\", \"bulldozer\", \"butterfly\", \"cactus\", \"cake\", \"calculator\", \"camel\", \"cannon\", \"canoe\", \"car-tire\", \"cartman\", \"cd\", \"centipede\", \"cereal-box\", \"chandelier-101\", \"chess-board\", \"chimp\", \"chopsticks\", \"cockroach\", \"coffee-mug\", \"coffin\", \"coin\", \"comet\", \"computer-keyboard\", \"computer-monitor\", \"computer-mouse\", \"conch\", \"cormorant\", \"covered-wagon\", \"cowboy-hat\", \"crab-101\", \"desk-globe\", \"diamond-ring\", \"dice\", \"dog\", \"dolphin-101\", \"doorknob\", \"drinking-straw\", \"duck\", \"dumb-bell\", \"eiffel-tower\", \"electric-guitar-101\", \"elephant-101\", \"elk\", \"ewer-101\", \"eyeglasses\", \"fern\", \"fighter-jet\", \"fire-extinguisher\", \"fire-hydrant\", \"fire-truck\", \"fireworks\", \"flashlight\", \"floppy-disk\", \"football-helmet\", \"french-horn\", \"fried-egg\", \"frisbee\", \"frog\", \"frying-pan\", \"galaxy\", \"gas-pump\", \"giraffe\", \"goat\", \"golden-gate-bridge\", \"goldfish\", \"golf-ball\", \"goose\", \"gorilla\", \"grand-piano-101\", \"grapes\", \"grasshopper\", \"guitar-pick\", \"hamburger\", \"hammock\", \"harmonica\", \"harp\", \"harpsichord\", \"hawksbill-101\", \"head-phones\", \"helicopter-101\", \"hibiscus\", \"homer-simpson\", \"horse\", \"horseshoe-crab\", \"hot-air-balloon\", \"hot-dog\", \"hot-tub\", \"hourglass\", \"house-fly\", \"human-skeleton\", \"hummingbird\", \"ibis-101\", \"ice-cream-cone\", \"iguana\", \"ipod\", \"iris\", \"jesus-christ\", \"joy-stick\", \"kangaroo-101\", \"kayak\", \"ketch-101\", \"killer-whale\", \"knife\", \"ladder\", \"laptop-101\", \"lathe\", \"leopards-101\", \"license-plate\", \"lightbulb\", \"light-house\", \"lightning\", \"llama-101\", \"mailbox\", \"mandolin\", \"mars\", \"mattress\", \"megaphone\", \"menorah-101\", \"microscope\", \"microwave\", \"minaret\", \"minotaur\", \"motorbikes-101\", \"mountain-bike\", \"mushroom\", \"mussels\", \"necktie\", \"octopus\", \"ostrich\", \"owl\", \"palm-pilot\", \"palm-tree\", \"paperclip\", \"paper-shredder\", \"pci-card\", \"penguin\", \"people\", \"pez-dispenser\", \"photocopier\", \"picnic-table\", \"playing-card\", \"porcupine\", \"pram\", \"praying-mantis\", \"pyramid\", \"raccoon\", \"radio-telescope\", \"rainbow\", \"refrigerator\", \"revolver-101\", \"rifle\", \"rotary-phone\", \"roulette-wheel\", \"saddle\", \"saturn\", \"school-bus\", \"scorpion-101\", \"screwdriver\", \"segway\", \"self-propelled-lawn-mower\", \"sextant\", \"sheet-music\", \"skateboard\", \"skunk\", \"skyscraper\", \"smokestack\", \"snail\", \"snake\", \"sneaker\", \"snowmobile\", \"soccer-ball\", \"socks\", \"soda-can\", \"spaghetti\", \"speed-boat\", \"spider\", \"spoon\", \"stained-glass\", \"starfish-101\", \"steering-wheel\", \"stirrups\", \"sunflower-101\", \"superman\", \"sushi\", \"swan\", \"swiss-army-knife\", \"sword\", \"syringe\", \"tambourine\", \"teapot\", \"teddy-bear\", \"teepee\", \"telephone-box\", \"tennis-ball\", \"tennis-court\", \"tennis-racket\", \"theodolite\", \"toaster\", \"tomato\", \"tombstone\", \"top-hat\", \"touring-bike\", \"tower-pisa\", \"traffic-light\", \"treadmill\", \"triceratops\", \"tricycle\", \"trilobite-101\", \"tripod\", \"t-shirt\", \"tuning-fork\", \"tweezer\", \"umbrella-101\", \"unicorn\", \"vcr\", \"video-projector\", \"washing-machine\", \"watch-101\", \"waterfall\", \"watermelon\", \"welding-mask\", \"wheelbarrow\", \"windmill\", \"wine-bottle\", \"xylophone\", \"yarmulke\", \"yo-yo\", \"zebra\", \"airplanes-101\", \"car-side-101\", \"faces-easy-101\", \"greyhound\", \"tennis-shoes\", \"toad\", \"clutter\"};\n",
    "List<String> categories = categoriesArray.ToList();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoke the Endpoint to get an Inference for the first image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MemoryStream dataStream = new MemoryStream(File.ReadAllBytes(@\"./008_0007.jpg\"));\n",
    "InvokeEndpointRequest invReq = new InvokeEndpointRequest(){\n",
    "    EndpointName = epName,\n",
    "    ContentType = \"application/x-image\",\n",
    "    Body = dataStream\n",
    "};\n",
    "InvokeEndpointResponse invResp = await smrClient.InvokeEndpointAsync(invReq);\n",
    "\n",
    "//Read the response stream back into a astring so it can be reviewed\n",
    "StreamReader sr = new StreamReader(invResp.Body);\n",
    "String responseBody = sr.ReadToEnd();\n",
    "\n",
    "//Load the values into a List so they can be more easily searched\n",
    "List<Decimal> probabilities = JsonConvert.DeserializeObject<List<Decimal>>(responseBody);\n",
    "\n",
    "//Determine which category returned the highest Probability match and print it's value and Index \n",
    "var indexAtMax = probabilities.IndexOf(probabilities.Max());\n",
    "Console.WriteLine(String.Format(\"Index of Max Probability: {0}\",indexAtMax));\n",
    "Console.WriteLine(String.Format(\"Value of Max Probability: {0}\",probabilities[indexAtMax]));\n",
    "\n",
    "//Print which Category name matches with the Image\n",
    "Console.WriteLine(String.Format(\"Category of Image : {0}\",categories[indexAtMax]));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoke the Endpoint to get an Inference for the first image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MemoryStream dataStream2 = new MemoryStream(File.ReadAllBytes(@\"./008_0009.jpg\"));\n",
    "InvokeEndpointRequest invReq2 = new InvokeEndpointRequest(){\n",
    "    EndpointName = epName,\n",
    "    ContentType = \"application/x-image\",\n",
    "    Body = dataStream2\n",
    "};\n",
    "InvokeEndpointResponse invResp2 = await smrClient.InvokeEndpointAsync(invReq2);\n",
    "\n",
    "//Read the response stream back into a astring so it can be reviewed\n",
    "StreamReader sr2 = new StreamReader(invResp2.Body);\n",
    "String responseBody2 = sr2.ReadToEnd();\n",
    "\n",
    "//Load the values into a List so they can be more easily searched\n",
    "List<Decimal> probabilities2 = JsonConvert.DeserializeObject<List<Decimal>>(responseBody2);\n",
    "\n",
    "//Determine which category returned the highest Probability match and print it's value and Index \n",
    "var indexAtMax2 = probabilities2.IndexOf(probabilities2.Max());\n",
    "Console.WriteLine(String.Format(\"Index of Max Probability: {0}\",indexAtMax2));\n",
    "Console.WriteLine(String.Format(\"Value of Max Probability: {0}\",probabilities2[indexAtMax2]));\n",
    "\n",
    "//Print which Category name matches with the Image\n",
    "Console.WriteLine(String.Format(\"Category of Image : {0}\",categories[indexAtMax2]));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DeleteEndpointRequest delReq = new DeleteEndpointRequest(){\n",
    "    EndpointName = epName\n",
    "};\n",
    "DeleteEndpointResponse delResp = await smClient.DeleteEndpointAsync(delReq);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "file_extension": ".cs",
   "mimetype": "text/x-csharp",
   "name": "C#",
   "pygments_lexer": "csharp",
   "version": "8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
